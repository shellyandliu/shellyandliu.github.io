<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="会飞的猪">





<link rel="stylesheet" href="/fonts/iconfont_new/iconfont.css">


<title>带约束的线性回归问题与多重共线性 | 会飞的猪</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 4.2.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">会飞的猪</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/categories">分类</a>
                
                    <a class="menu-item" href="/tags">标签</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">会飞的猪</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/categories">分类</a>
                
                    <a class="menu-item" href="/tags">标签</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">展开目录</a>
        <a onclick="go_top()">回到顶部</a>
        <a onclick="go_bottom()">到达底部</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">带约束的线性回归问题与多重共线性</h1>
            
                <div class="post-meta">
                    
                        作者: <a itemprop="author" rel="author" href="/">会飞的猪</a>
                    

                    
                        <span class="post-time">
                        时间: <a href="#">四月 16, 2020&nbsp;&nbsp;17:33:23</a>
                        </span>
                    
                    
                        <span class="post-category">
                    类别:
                            
                                <a href="/categories/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">-线性回归</a>
                            
                        </span>
                    
                    
                        <span class="post-time">
                            <span class="post-meta-item-icon">
                              <i class="fa fa-keyboard-o"></i>
                              <span class="post-meta-item-text">  字数统计: </span>
                              <span class="post-count"><a href="#">1.9k字</a></span>
                            </span>
                        </span>
                        <span class="post-time">
                            <span class="post-meta-item-icon">
                            <i class="fa fa-hourglass-half"></i>
                            <span class="post-meta-item-text">  阅读时长: </span>
                            <span class="post-count"><a href="#">9分</a></span>
                            </span>
                        </span>
                    

                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="带约束的线性回归"><a href="#带约束的线性回归" class="headerlink" title="带约束的线性回归"></a>带约束的线性回归</h2><p>回归方程为：</p>
<blockquote>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}y=X \beta+\epsilon \\ H \beta=c \\ E(\epsilon)=0, \operatorname{var}(\epsilon)=\sigma^{2} I_{n}\end{array}, \operatorname{dim}(H)=q \times(m+1), r(H)=q \leq m+1\right.</script></blockquote>
<h3 id="beta-最小二乘估计"><a href="#beta-最小二乘估计" class="headerlink" title="$\beta$ 最小二乘估计"></a>$\beta$ 最小二乘估计</h3><p>对该约束问题，运用拉格朗日乘子法：$L=(y-X\beta)’(y-X\beta)+\lambda^T(H\beta-c)$ ,对其求一阶偏导，可得：</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}2 X^{T} y+2 X^{T} X \beta+H^{T} \lambda=0 \\ H \beta-c=0\end{array}\right.</script><p>解这个方程组，最终可以得到：</p>
<blockquote>
<p>$\hat {\beta}_H=\hat{\beta}+(X’X)^{-1}H’[H(X’X)^{-1}H’]^{-1}(c-H\hat{\beta})$</p>
</blockquote>
<p>另一方面，由于：</p>
<blockquote>
<p>$L=(y-X\beta)’(y-X\beta)=(y-X\hat{\beta}+X\hat{\beta}-X\beta)’(y-X\hat{\beta}+X\hat{\beta}-X\beta)$</p>
<p>$=(y-X\hat{\beta})’(y-X\hat{\beta})+(\hat{\beta}-\beta)’X’X(\hat{\beta}-\beta)=(y-X\hat{\beta})’(y-X\hat{\beta})+(\hat{\beta}-\hat{\beta}_H+\hat{\beta}_H-\beta)’X’X(\hat{\beta}-\hat{\beta}_H+\hat{\beta}_H-\beta)$</p>
<p>$=(y-X\hat{\beta})’(y-X\hat{\beta})+(\hat{\beta}-\hat{\beta}_H)’X’X(\hat{\beta}-\hat{\beta}_H)+(\hat{\beta}_H-\beta)’X’X(\hat{\beta}_H-\beta)$</p>
</blockquote>
<p>显然在 $\beta=\hat{\beta}_H$ 时取得最小值。说明了 $\hat{\beta}_H$ 的合理性。</p>
<h3 id="参数的统计性质"><a href="#参数的统计性质" class="headerlink" title="参数的统计性质"></a>参数的统计性质</h3><blockquote>
<p>引理1：$\hat{\beta}_H\sim N(\beta,\sigma^2G)$， 其中 $G=(X’X)\{I-H’[H(X’X)^{-1}H’]^{-1}H(X’X)^{-1}\}$</p>
<p>引理2：若 $\hat y_H=X\hat{\beta}_H, e_H=y-\hat y_H$， 那么 $e_H\sim N(0,\sigma^2(I-XGX^T))$</p>
</blockquote>
<p><strong>引理1：</strong></p>
<p>由于 $\hat{\beta}_H$ 关于 $\hat{\beta}$ 是线性的，所以 $\hat{\beta}_H$ 也是正态分布。</p>
<blockquote>
<p>$E(\hat{\beta}_H)=E(\hat{\beta})+(X’X)^{-1}H’[H(X’X)^{-1}H’]^{-1}(c-HE(\hat{\beta}))=\beta$</p>
<p>$var(\hat{\beta}_H)=var([I-(X’X)^{-1}H’[H(X’X)^{-1}H’]^{-1}H]\hat{\beta}+c)=$</p>
<p>$[I-(X’X)^{-1}H’[H(X’X)^{-1}H’]^{-1}H]\sigma^2(X’X)^{-1}[I-(X’X)^{-1}H’[H(X’X)^{-1}H’]^{-1}H]’=\sigma^2G$</p>
</blockquote>
<p><strong>引理2：</strong></p>
<p>由于 $y-\hat y_H$ 关于 $y$ 是线性的，所以也是服从正态分布。</p>
<blockquote>
<p>$E(e_H)=0$</p>
<p>$cov(e_H,\hat{\beta}_H)=cov(y-X\hat{\beta}_H,\hat{\beta}_H)=cov(y,\hat{\beta}_H)-Xcov(\hat{\beta}_H,\hat{\beta}_H)=0$</p>
<p>$var(e_H)=var(y)-var(\hat y_H)-2cov(e_H,X\hat{\beta}_H)=\sigma^2-\sigma^2(XGX^T)$</p>
</blockquote>
<h3 id="残差平方和及显著性检验"><a href="#残差平方和及显著性检验" class="headerlink" title="残差平方和及显著性检验"></a>残差平方和及显著性检验</h3><h4 id="残差平方和"><a href="#残差平方和" class="headerlink" title="残差平方和"></a>残差平方和</h4><blockquote>
<p>$SSE_H=SSE+(\hat{\beta}-\hat{\beta}_H)’X’X(\hat{\beta}-\hat{\beta}_H)$</p>
<p>$=S S E+\left\{\left(X^{\prime} X\right)^{-1} H^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1}(c-H \hat{\beta})\right\}^{\prime} X^{\prime} X\left\{\left(X^{\prime} X\right)^{-1} H^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1}(c-H \hat{\beta})\right\}$</p>
<p>$=S S E+(c-H \hat{\beta})^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1}(c-H \hat{\beta})$</p>
<p>$E(SSE_H)=E(SSE)+E\left[(c-H \hat{\beta})^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1}(c-H \hat{\beta})\right]$</p>
<p>$=E(SSE)+\operatorname{tr}\left\{E\left\{\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1}(c-H \hat{\beta})^{\prime}(c-H \hat{\beta})\right\}\right\}$</p>
<p>$=E(SSE)+\operatorname{tr}\left\{\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1} \operatorname{var}(c-H \hat{\beta})\right\}$</p>
<p>$=E(SSE)+r(H)\sigma^2=(n-m-1+q)\sigma^2$</p>
</blockquote>
<h4 id="显著性检验"><a href="#显著性检验" class="headerlink" title="显著性检验"></a>显著性检验</h4><p>原假设为：</p>
<blockquote>
<p>$H_0:c=H\beta$</p>
</blockquote>
<p>由于：$\frac{SSE_H-S S E}{\sigma^2}=(\frac{c-H \hat{\beta}}{\sigma})^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1}(\frac{c-H \hat{\beta}}{\sigma})$, 令$X=\frac{c-H \hat{\beta}}{\sigma}$, $A=\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1}$, 则 $\frac{SSE_H-S S E}{\sigma^2}=X^TAX$, 由于 $\operatorname{var}(X)=H\left(X^{\prime} X\right)^{-1} H^{\prime}$, $E(X)=0$，且 $Avar(X)A=A$.则可推得：</p>
<blockquote>
<p>$\frac{SSE_H-S S E}{\sigma^2}\sim \chi^2(q)$</p>
</blockquote>
<p>最终的统计分布为：</p>
<blockquote>
<p>$F=\frac{(SSE_H-SSE)/q}{SSE/(n-m-1)}\sim F(q,n-m-1)$</p>
</blockquote>
<p>当$c=0$时</p>
<blockquote>
<p>$\hat{y}_{H}=X \hat{\beta}-X\left(X^{\prime} X\right)^{-1} H^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1} H \hat{\beta}=\left\{X\left(X^{\prime} X\right)^{-1} X^{\prime}-X\left(X^{\prime} X\right)^{-1} H^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1} H\left(X^{\prime} X\right)^{-1} X^{\prime}\right\} y$</p>
</blockquote>
<p>令 $P_X=X\left(X^{\prime} X\right)^{-1} X^{\prime}$, $P_1=X\left(X^{\prime} X\right)^{-1} H^{\prime}\left[H\left(X^{\prime} X\right)^{-1} H^{\prime}\right]^{-1} H\left(X^{\prime} X\right)^{-1} X^{\prime}$, $P_H=P_X-P_1$</p>
<p>则：$SSE_H=y’(I-P_H)’(I-P_H)y=y’(I-P_H)y$</p>
<p>因此统计量为：</p>
<blockquote>
<p>$F=\frac{n-m-1}{q}\frac{y’(P_X-P_H)y}{y’(I-P_X)y}$</p>
</blockquote>
<h2 id="多重共线性"><a href="#多重共线性" class="headerlink" title="多重共线性"></a>多重共线性</h2><blockquote>
<p>定义：如果存在不全为 $0$ 的 $p+1$ 个数 $c_0,c_1,\dots,c_p$ ，使得 $c_0+c_1x_{i1}+\dots+c_px_{ip}=0\quad i=1,2,\dots,n$ ,则称自变量 $x_1,x_2,\dots,x_p$  之间存在<strong>完全多重共线性</strong>。</p>
<p>如果改为 $c_0+c_1x_{i1}+\dots+c_px_{ip}\approx 0\quad i=1,2,\dots,n$ ，则称自变量具有<strong>多重共线性</strong></p>
</blockquote>
<p>在完全多重共线性的情况下，设计矩阵 $X$ 不是列满秩的，自然 $X’X$ 是不可逆的。这时 $\hat{\beta}$ 不存在。而如果时多重共线性的情况下，$|X’X|\approx 0$, 意味着$(X’X)^{-1}$的对角线元素很大，而 $D(\hat{\beta})=\sigma^2(X’X)^{-1}$, 意味着某些估计的参数的方差会很大。回归系数的正负号<strong>可能会产生倒置</strong>。</p>
<p>另一方面在多重共线性得情况下可能会存在一对相关性强的变量，它们系数取值符号相反，但绝对值差不多大，会大大增加方差，这也就是高方差的体现，但其实它们的合作用效果近似为 $0$ ，这将大大降低模型得可解释性。</p>
<h3 id="多重共线性的诊断"><a href="#多重共线性的诊断" class="headerlink" title="多重共线性的诊断"></a>多重共线性的诊断</h3><h4 id="方差扩大因子法"><a href="#方差扩大因子法" class="headerlink" title="方差扩大因子法"></a>方差扩大因子法</h4><p>对自变量做中心标准化 $x_{ij}^{*}=\frac{x_{ij}-\bar{x}_j}{\sqrt{L_{jj}}}$, 则可以得到：$r=(X^{*})’X^{*}$ ,为了方便记 $X=X^{*}$ , $C=\left(X’X\right)^{-1}$ ,则可以得到 $\hat{\beta}_j$ 标准化后的方差表达式</p>
<blockquote>
<p>$var(\hat{\beta}_j)=c_{jj}\sigma^2/L_{jj}$</p>
</blockquote>
<p>其中，这里的 $c_{jj}$ 被称为方差系数，所以定义它就是<strong>方差扩大因子</strong>，记为 $VIF_j$</p>
<blockquote>
<p>$c_{jj}=\frac{1}{1-R_j^2}$</p>
<p>其中 $R_j^2$ 是自变量 $x_j$ 对于其他 $p-1$ 个自变量的复决定系数，即实际上可以得到 $VIF_j\ge 1$</p>
</blockquote>
<p>考虑 $j=1$ ，将 $X_1$ 视为因变量 $x_1$ 的 $n$ 次观测，$X_0$ 为其余 $m-1$ 个自变量的观测，考虑线性回归模型：</p>
<blockquote>
<p>$X_1=X_0\beta_0+\epsilon$, $E(\epsilon)=0,cov(\epsilon)=\sigma^2I$</p>
</blockquote>
<p>由于 $X$ 已经中心标准化，因此对于此模型的总平方和 $SST=\sum_{i=1}^n(x_{1i}-\bar{x}_1)^2=X_1’X_1=1$，回归平方和 $SSR=\hat{\beta}_0’X_0’X_1=X_1’X_0(X_0’X_0)^{-1}X_0’X_1$，因此$R_1^2=\frac{SSR}{SST}=\hat{\beta}_0’X_0’X_1=X_1’X_0(X_0’X_0)^{-1}X_0’X_1$, 又因为：</p>
<script type="math/tex; mode=display">
C=\left[\begin{array}{cc}X_{1}^{\prime} X_{1} & X_{1}^{\prime} X_{0} \\ X_{0}^{\prime} X_{1} & X_{0}^{\prime} X_{0}\end{array}\right]^{-1}=\left[\begin{array}{cc}(1-X_{1}^{\prime} X_0(X_0'X_0)^{-1}X_0'X_{1})^{-1} & * \\* & *\end{array}\right]</script><p>则 $c_{11}=\frac{1}{1-R_1^2}$</p>
<p>在经验上，<strong>当 $VIF_j\ge10$ 时，就认为存在严重的多重共线性</strong></p>
<p>另外一种方法是计算 $\overline{VIF}=\frac 1p\sum_{j=1}^pVIF_{j}$，如果它远大于1，就说明可能存在严重的多重共线性。</p>
<p>上述判断都需要在样本容量相对较大的情况下进行。</p>
<h4 id="特征根判定法"><a href="#特征根判定法" class="headerlink" title="特征根判定法"></a>特征根判定法</h4><blockquote>
<p>设 $X’X$的最大特征根为 $\lambda_m$ ，则称 $k_i=\sqrt{\frac{\lambda_m}{\lambda_i}}$ 为特征根 $\lambda_i$ 的条件数。</p>
</blockquote>
<p>在经验上，如果 $0&lt;k&lt;10$ 就认为无多重共线性，$10&lt;k&lt;100$ 则认为存在较强的多重共线性，而 $k\ge100$ 就认为存在严重的多重共线性。</p>
<p>解决多重共线性的方法最简单的有 :<strong>通过数据剔除不重要的解释变量</strong>和<strong>增大样本容量</strong></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><hr>
<p>[1] 何晓群，刘文卿. 应用回归分析[M]. 中国人民大学出版社，2015.3</p>
<p>[2] 孙荣恒. 应用数理统计.科学出版社，1998</p>
<p>[3] 陈希孺，王松桂. 近代回归分析-原理方法及应用.安徽教育出版社，1987</p>
<p>[4] <a href="https://zhuanlan.zhihu.com/p/50792150" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/50792150</a></p>

        </div>
        
            <div style="text-align:center;color: rgb(125,125,125);font-size:14px;">
               -------------本文结束 感谢您的阅读-------------
            </div>
        
        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>文章作者:</span>
                        <span>会飞的猪</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>文章链接:</span>
                        <span><a href="http://shellyandliu.github.io/2020/04/16/%E5%B8%A6%E7%BA%A6%E6%9D%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7/">http://shellyandliu.github.io/2020/04/16/%E5%B8%A6%E7%BA%A6%E6%9D%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>版权声明:</span>
                        <span>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC-BY-NC-4.0</a> ， 转载请注明来自 会飞的猪！</span>
                    </p>
                
            </section>
        
        <section class="post-tags">
            <div>
                <span>标签:</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"> <i class="iconfont icon-tags"></i> 机器学习</a>
                    
                        <a href="/tags/%E7%BB%9F%E8%AE%A1/"> <i class="iconfont icon-tags"></i> 统计</a>
                    
                        <a href="/tags/%E4%BC%98%E5%8C%96/"> <i class="iconfont icon-tags"></i> 优化</a>
                    
                        <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"> <i class="iconfont icon-tags"></i> 线性回归</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">返回</a>
                <span> /  </span>
                <a href="/">首页</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2020/04/16/%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%92%8C%E5%B9%BF%E4%B9%89%E5%B2%AD%E5%9B%9E%E5%BD%92/">岭回归和广义岭回归</a>
            
            
            <a class="next" rel="next" href="/2020/04/16/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8F%98%E9%87%8F%E9%80%89%E6%8B%A9/">线性回归的变量选择</a>
            
        </section>
        <div class="post-content">
            <section style="font-size: 20px;font-weight: 700;margin-bottom: 10px;margin-top: 20px;">
                <i class="iconfont icon-comments"></i>
                <span>
                    评论
                </span>
            </section>
        </div>
        
            <section id="comments" class="comments">
              <style>
                .comments{margin:0px;padding:10px;background:#fff}
                @media screen and (max-width:800px){.comments{margin:auto;padding:10px;background:#fff}}
              </style>
              <div class="valine_comment"></div>
<!--����js����</body>֮ǰ���뼴��-->
<!--Leancloud ������:-->
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<!--Valine �ĺ��Ĵ����-->
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
  new Valine({
      el: '.valine_comment',
      app_id: 'bCvyxhtL2V59mmqAp81lAGob-gzGzoHsz#Leancloud应用的appId',
      app_key: 'J4zVKQfUjhToGJwBfLcoOHOv',
      placeholder: '欢迎大家评论交流~',
      notify: 'true',
      verify: 'true',
    });
</script>
            </section>
        
        

    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© 会飞的猪 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>

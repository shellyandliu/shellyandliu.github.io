<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="会飞的猪">





<link rel="stylesheet" href="/fonts/iconfont_new/iconfont.css">


<title>Logistic回归 | 会飞的猪</title>



    <link rel="icon" href="/image/longmao.jpg">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 4.2.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">会飞的猪</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/categories">分类</a>
                
                    <a class="menu-item" href="/tags">标签</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">会飞的猪</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/categories">分类</a>
                
                    <a class="menu-item" href="/tags">标签</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">展开目录</a>
        <a onclick="go_top()">回到顶部</a>
        <a onclick="go_bottom()">到达底部</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Logistic回归</h1>
            
                <div class="post-meta">
                    
                        作者: <a itemprop="author" rel="author" href="/">会飞的猪</a>
                    

                    
                        <span class="post-time">
                        时间: <a href="#">五月 13, 2020&nbsp;&nbsp;21:31:13</a>
                        </span>
                    
                    
                        <span class="post-category">
                    类别:
                            
                                <a href="/categories/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/">-线性分类模型</a>
                            
                        </span>
                    
                    
                        <span class="post-time">
                            <span class="post-meta-item-icon">
                              <i class="fa fa-keyboard-o"></i>
                              <span class="post-meta-item-text">  字数统计: </span>
                              <span class="post-count"><a href="#">1.2k字</a></span>
                            </span>
                        </span>
                        <span class="post-time">
                            <span class="post-meta-item-icon">
                            <i class="fa fa-hourglass-half"></i>
                            <span class="post-meta-item-text">  阅读时长: </span>
                            <span class="post-count"><a href="#">4分</a></span>
                            </span>
                        </span>
                    

                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="线性分类模型"><a href="#线性分类模型" class="headerlink" title="线性分类模型"></a>线性分类模型</h1><p>在分类问题中，对类别标签的表示有不同的方式。对于概率模型来说，在二分类问题中，最方便的表示方法是二元表示方法，在这种表示方法中，将目标值取为 $\{0, 1\}$ ，当 $ y = 1$ 代表类别 $\mathcal C_1$ ，当 $y = 0$ 时代表类别 $\mathcal C_2$ 。我们可以把 $y$ 的值看成分类结果为 $\mathcal C_1$ 的概率，这个概率只取极端的值 $0$ 和$1$ 。对于多分类问题，比较方便的方法是使用 “1-of-K”编码规则。这种⽅法中，$y$ 是⼀个长度为 $K$ 的向量。如果类别为$\mathcal C_j$，那么 $y$ 的所有元素 $y_k$ 中，只有 $y_j$ 等于 $1$。</p>
<p>对于线性回归模型，模型的输出变量对输入变量时线性的，即 $ z=w^Tx+w_0$ , 而对于分类问题，我们想要预测的是离散的类别标签，或者更一般的，预测位于 $(0,1)$ 区间的后验概率分布，因此需要对线性模型进行推广，即使用非线性函数 $f(\cdot)$ 对 $w$ 的线性函数做变换，即:</p>
<blockquote>
<script type="math/tex; mode=display">
y(x) = f(w^Tx+w_0)\tag{1}</script></blockquote>
<p>其中 $f$ 一般被称为激活函数，决策面对应于 $y(x)=$  常数  , 即 $w^Tx+w_0=$ 常数 ，因此决策面是关于 $x$ 的线性函数，该模型被称为线性分类模型</p>
<h1 id="二分类下的Logistic回归"><a href="#二分类下的Logistic回归" class="headerlink" title="二分类下的Logistic回归"></a>二分类下的Logistic回归</h1><h2 id="Sigmod函数"><a href="#Sigmod函数" class="headerlink" title="Sigmod函数"></a>Sigmod函数</h2><p>对于二分类任务，我们记输出 $y\in\{0,1\}$，由于线性回归模型 $z=w^T x+w_0$ 产生的预测值是连续的，因此需要将 $z$ 转化为 $0/1$ 值得，最理想得激活函数就是单位阶跃函数:</p>
<blockquote>
<script type="math/tex; mode=display">
f(z)=\left\{\begin{array}{ll}
0, & z<0 \\
0.5, & z=0 \\
1, & z>0
\end{array}\right.\tag{2}</script></blockquote>
<p>但是由于单位阶跃函数不连续，因此不能直接使用，因此我们希望找到能在一定程度上近似单位阶跃函数，并且希望它单调可微。sigmod函数正是这样的选择：</p>
<blockquote>
<script type="math/tex; mode=display">
f(z)=\frac 1{1+e^{-z}}\tag{3}</script></blockquote>
<p>因此</p>
<blockquote>
<script type="math/tex; mode=display">
f(x)=\frac{1}{1+e^{-(w^Tx+w_0)}}\tag{4}</script></blockquote>
<p>将 (4) 式写成反函数的形式：</p>
<blockquote>
<script type="math/tex; mode=display">
\ln\frac{f(x)}{1-f(x)}=w^Tx+w_0</script></blockquote>
<p>若将 $f(x)$ 视为 $x$ 作为正类的可能性，即 $f(x)=P(y=1|x)$，则 $1-f(x)$ 就为 $x$ 作为反类的可能性，因此两者的比值（称为“几率”）就反映了 $x$ 作为正类的相对可能性，所以Logistic回归也叫做对数几率回归。</p>
<p>二分类的Logistic回归的条件概率如下：</p>
<blockquote>
<script type="math/tex; mode=display">
\begin{aligned}
&P(y=1|x)=\frac{e^{w^Tx+w_0}}{1+e^{w^Tx+w_0}}\\
&P(y=0|x)=\frac{1}{1+e^{w^Tx+w_0}}
\end{aligned}</script></blockquote>
<p>为方便起见，记 $\beta=(w;w_0),\hat{x}=(x;1)$, 则$w^Tx+w_0=\beta^T\hat x$</p>
<h2 id="模型的参数估计"><a href="#模型的参数估计" class="headerlink" title="模型的参数估计"></a>模型的参数估计</h2><p>考虑使用极大似然估计法估计参数，设 $\{x_i,y_i\}_n$ 为训练数据。则似然函数为：</p>
<blockquote>
<script type="math/tex; mode=display">
L(\beta)=\prod_{i=1}^n[P(y_i=1|x_i)]^{y_i}[P(y_i=0|x_i)]^{1-y_i}</script></blockquote>
<p>因此负的对数似然函数为：</p>
<blockquote>
<script type="math/tex; mode=display">
L'(\beta)=-\sum_{i=1}^ny_i\log P(y_i=1|x_i)+(1-y_i)\log P(y_i=0|x_i)\tag{5}</script></blockquote>
<p>显然，$L’(\beta)$ 是关于 $\beta$ 的凸函数，则经典的数值优化方法均可以采用，如梯度下降法和牛顿法。</p>
<p>令 $p_i=P(y_i=1|x)$ , 则 $L’(\beta)$ 的一阶偏导为：</p>
<blockquote>
<script type="math/tex; mode=display">
\frac{\partial L'(\beta)}{\partial \beta}=\sum_{i=1}^n(p_i-y_i)x_i</script></blockquote>
<p>因此梯度下降算法每步的迭代为:</p>
<blockquote>
<script type="math/tex; mode=display">
\beta_{k+1}=\beta_k-\alpha_k\sum_{i=1}^n(p_i-y_i)x_i</script></blockquote>
<p>其中 $\alpha_k$ 为学习率。</p>
<p>我们注意到，当数据集为线性可分的时候，极大似然法会产生严重的过拟合现象，这时 $w$ 的大小将趋于无穷大。因此需要正则化。</p>
<h1 id="多分类的Logistic回归"><a href="#多分类的Logistic回归" class="headerlink" title="多分类的Logistic回归"></a>多分类的Logistic回归</h1><p>假设 $y$ 有 $K$ 个类别，则多分类Logistic回归模型为：</p>
<blockquote>
<script type="math/tex; mode=display">
P(y\in \mathcal C_k|x)=\frac{\exp(\beta_k\cdot x)}{\sum_{k=1}^K\exp(\beta_k\cdot x)}</script></blockquote>
<p>该函数也称为softmax函数。</p>
<p>对于 $y$ 最容易的表示方法为 1-of-K 表示方法。即属于类别 $\mathcal C_k$ 的特征向量 $x$ 的目标向量 $y$ 是一个二元向量，其中第 $k$ 个元素为 $1$,其余元素为 $0$.  因此，在这种情况下，似然函数为：</p>
<blockquote>
<script type="math/tex; mode=display">
L(\beta_1,\cdots,\beta_k)=\prod_{i=1}^n\prod_{k=1}^KP(y_i\in\mathcal C_k|x_i)^{y_{ik}}</script></blockquote>
<p>因此其负对数似然函数为：</p>
<blockquote>
<script type="math/tex; mode=display">
L(\beta_1,\cdots,\beta_k)=-\sum_{i=1}^n\sum_{k=1}^Ky_{ik}\ln P(y_i\in\mathcal C_k|x_i)</script></blockquote>
<p>因此关于参数向量 $\beta_j$ 的梯度为：</p>
<blockquote>
<script type="math/tex; mode=display">
\frac{\partial L'(\beta_1,\cdots,\beta_k)}{\partial \beta_j}=\sum_{i=1}^n(P(y_i\in\mathcal C_k|x_i)-y_{ij})x_i</script></blockquote>
<hr>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] 周志华. 机器学习. 清华大学出版社，2016.1</p>
<p>[2] 李航. 统计学习方法. 清华大学出版社，2019</p>
<p>[3] Bishop, Christopher M. <em>Pattern recognition and machine learning</em>. springer, 2006.</p>

        </div>
        
            <div style="text-align:center;color: rgb(125,125,125);font-size:14px;">
               -------------本文结束 感谢您的阅读-------------
            </div>
        
        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>文章作者:</span>
                        <span>会飞的猪</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>文章链接:</span>
                        <span><a href="http://shellyandliu.github.io/2020/05/13/Logistic%E5%9B%9E%E5%BD%92/">http://shellyandliu.github.io/2020/05/13/Logistic%E5%9B%9E%E5%BD%92/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>版权声明:</span>
                        <span>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC-BY-NC-4.0</a> ， 转载请注明来自 会飞的猪！</span>
                    </p>
                
            </section>
        
        <section class="post-tags">
            <div>
                <span>标签:</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"> <i class="iconfont icon-tags"></i> 机器学习</a>
                    
                        <a href="/tags/%E7%BB%9F%E8%AE%A1/"> <i class="iconfont icon-tags"></i> 统计</a>
                    
                        <a href="/tags/%E4%BC%98%E5%8C%96/"> <i class="iconfont icon-tags"></i> 优化</a>
                    
                        <a href="/tags/%E5%88%86%E7%B1%BB/"> <i class="iconfont icon-tags"></i> 分类</a>
                    
                        <a href="/tags/Logistic%E5%9B%9E%E5%BD%92/"> <i class="iconfont icon-tags"></i> Logistic回归</a>
                    
                        <a href="/tags/softmax%E5%87%BD%E6%95%B0/"> <i class="iconfont icon-tags"></i> softmax函数</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">返回</a>
                <span> /  </span>
                <a href="/">首页</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2020/05/14/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/">线性判别分析（LDA）</a>
            
            
            <a class="next" rel="next" href="/2020/05/10/%E7%89%9B%E9%A1%BF%E6%B3%95/">牛顿法</a>
            
        </section>
        <div class="post-content">
            <section style="font-size: 20px;font-weight: 700;margin-bottom: 10px;margin-top: 20px;">
                <i class="iconfont icon-comments"></i>
                <span>
                    评论
                </span>
            </section>
        </div>
        
            <section id="comments" class="comments">
              <style>
                .comments{margin:0px;padding:10px;background:#fff}
                @media screen and (max-width:800px){.comments{margin:auto;padding:10px;background:#fff}}
              </style>
              <div class="valine_comment"></div>
<!--����js����</body>֮ǰ���뼴��-->
<!--Leancloud ������:-->
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<!--Valine �ĺ��Ĵ����-->
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
  new Valine({
      el: '.valine_comment',
      app_id: 'bCvyxhtL2V59mmqAp81lAGob-gzGzoHsz#Leancloud应用的appId',
      app_key: 'J4zVKQfUjhToGJwBfLcoOHOv',
      placeholder: '欢迎大家评论交流~',
      notify: 'true',
      verify: 'true',
    });
</script>
            </section>
        
        

    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© 会飞的猪 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
